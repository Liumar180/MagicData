hadoop伪分布式集群配置(CentOS 7)(3.10.0-327.10.1.el7.x86_64)
一、配置系统环境
1、修改主机名
hostnamectl set-hostname mymaster
2、配置ssh免密码登陆
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
3、关闭防火墙
systemctl stop firewalld.service
4、在/etc/hosts中增加如下行
192.168.40.211  mymaster
5、修改文件句柄限制
ulimit -a
ulimit -n 2048
ulimit -a
二、安装jdk
1、查询已安装的open-jdk
rpm -qa | grep java
卸载open-jdk
rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.95-2.6.4.0.el7_2.x86_64
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.71-2.b15.el7_2.x86_64
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.71-2.b15.el7_2.x86_64
rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.71-2.b15.el7_2.x86_64
rpm -e --nodeps java-1.7.0-openjdk-1.7.0.95-2.6.4.0.el7_2.x86_64
2、安装jdk-8
tar zxvf jdk-8u65-linux-x64.tar.gz
配置环境变量，在/etc/profile结尾处添加如下行：
JAVA_HOME=/opt/bigdata/jdk1.8.0_65/
JRE_HOME=/opt/bigdata/jdk1.8.0_65/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
执行
source /etc/profile
三、安装hadoop
1、tar zxvf hadoop-2.6.3.tar.gz
2、修改目录/opt/bigdata/hadoop-2.6.3/etc/hadoop下的配置文件。
在core-site.xml中增加如下内容：
	<property>
	<name>fs.defaultFS</name>
	<value>hdfs://mymaster:8020/hbase</value>
	</property>
	<property>
	<name>hadoop.tmp.dir</name>
	<value>/data/hadoop/tmp</value>
	</property>
在hdfs-site.xml中增加如下内容：
	<property>
	<name>dfs.replication</name>
	<value>1</value>
	</property>
	<property>
	<name>dfs.namenode.name.dir</name>
	<value>file:///data/hadoop/dfs/name</value>
	</property>
	<property>
	<name>dfs.datanode.data.dir</name>
	<value>file:///data/hadoop/dfs/data</value>
	</property>
在mapred-site.xml中增加如下内容：
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
	</property>
	<property>
	<name>mapreduce.jobhistory.address</name>
	<value>mymaster:10020</value>
	</property>
	<property>
	<name>mapreduce.jobhistory.webapp.address</name>
	<value>mymaster:19888</value>
	</property>
在yarn-site.xml中增加如下内容：
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
	</property>
	<property>
	<name>mapreduce.jobhistory.address</name>
	<value>mymaster:10020</value>
	</property>
	<property>
	<name>mapreduce.jobhistory.webapp.address</name>
	<value>mymaster:19888</value>
	</property> 
在hadoop-env.sh中增加如下内容：
export JAVA_HOME=/opt/bigdata/jdk1.8.0_65/
3、配置环境变量，在/etc/profile结尾处添加如下行： 
export HADOOP_HOME=/opt/bigdata/hadoop-2.6.3
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
执行
source /etc/profile
4、格式化namenode
hdfs namenode -format
5、启动
start-all.sh
三、安装hbase
1、解压
tar zxvf hbase-1.0.2-bin.tar.gz
2、修改目录/opt/bigdata/hbase-1.0.2/conf下的配置文件。
在hbase-site.xml中增加如下行：
	<property>
	<name>hbase.rootdir</name>
	<value>hdfs://mymaster:8020/hbase</value>
	</property>
	<property>
	<name>hbase.cluster.distributed</name>
	<value>true</value>
	</property>
	<property>
	<name>hbase.zookeeper.quorum</name>
	<value>mymaster</value>
	</property>
3、配置环境变量，在/etc/profile结尾处添加如下行： 
export HBASE_HOME=/opt/bigdata/hbase-1.0.2
export PATH=$PATH:$HBASE_HOME/bin
执行
source /etc/profile
4、启动
start-hbase.sh
四、测试
